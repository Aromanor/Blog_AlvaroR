{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Acerca de mi\"\n",
        "author: \"Alvaro Romano\"\n",
        "date: \"2024-08-02\"\n",
        "categories: [news]\n",
        "---\n",
        "\n",
        "\n",
        "Esto es a primera vista algo de mi y mi proyecto de NLP:\n",
        "\n",
        "![](thumbnail.jpg)\n",
        "\n",
        "Me encuentro realizando un proyecto aplicado al afinamiento de una inteligencia artificial, para generar clasificaciones de texto académico en base a un entrenamiento con textos calificados y validados por medio de \"Inter-rater Analisis\".\n",
        "\n",
        "Partimos por instalar los paquetes necesarios en Python:\n"
      ],
      "id": "d590ae46"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pip install --upgrade pip\n",
        "pip install torch==1.11.0 transformers==4.18.0 datasets==2.2.2 accelerate==0.21.0\n",
        "pip install transformers datasets pandas openpyxl\n",
        "pip install transformers[torch] accelerate\n",
        "pip install accelerate -U\n",
        "pip install transformers torch pandas"
      ],
      "id": "ec0ad1ac",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Luego procedemos con la lectura de datos:\n"
      ],
      "id": "e9559c52"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el dataset\n",
        "dataset = pd.read_excel('ECO_1.xlsx')\n",
        "\n",
        "# Rellenar los NaN con cadenas vacías para evitar errores al combinar\n",
        "dataset[['Argumento o razón', 'Conclusión']] = dataset[['Argumento o razón', 'Conclusión']].fillna('')\n",
        "\n",
        "# Combinar los párrafos en una sola columna\n",
        "dataset['texto_completo'] = dataset[['Introducción','Argumento base' ,'Argumento o razón', 'Conclusión']].agg(' '.join, axis=1)\n",
        "\n",
        "# Seleccionar las columnas necesarias\n",
        "dataset = dataset[['ID', 'texto_completo', 'Descripción de nivel']]"
      ],
      "id": "da44b62d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Con esto lograremos adecuarlos con el fin de trabajarlos para su exploración:\n"
      ],
      "id": "d6ea490a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Codificar las etiquetas\n",
        "label_encoder = LabelEncoder()\n",
        "dataset['labels'] = label_encoder.fit_transform(dataset['Descripción de nivel'])\n",
        "\n",
        "# Resumen de la cantidad de datos en cada clase\n",
        "class_counts = dataset['Descripción de nivel'].value_counts()\n",
        "print(class_counts)\n",
        "\n",
        "# Gráfico de barras de la cantidad de datos en cada clase\n",
        "class_counts.plot(kind='bar')\n",
        "plt.title('Distribución de Clases')\n",
        "plt.xlabel('Clase')\n",
        "plt.ylabel('Cantidad')\n",
        "plt.show()\n",
        "\n",
        "# Dividir el dataset en entrenamiento y prueba\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    dataset['texto_completo'], dataset['labels'], test_size=0.2, random_state=42\n",
        ")"
      ],
      "id": "466434c5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "C:\\Users\\alvar\\AppData\\Roaming\\Python\\share\\jupyter\\kernels\\python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}